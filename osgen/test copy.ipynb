{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "from utils import describe_img\n",
    "from vae import VAEncoder, VAEDecoder\n",
    "from vcm import extract_style_emb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': ' The image presents a close-up view of a circular, pinkish-purple tissue sample. The tissue sample is composed of numerous small, dark pink/purple cells, which appear to be distributed throughout the circular shape. The cells are not uniformly distributed, with some areas showing a more dense concentration of cells. The background is a stark white, which contrasts with the pinkish-purple color of the tissue sample, making it stand out. The image does not contain any discernible text or additional objects, and the relative positions of the cells remain constant throughout the circular shape.'}\n",
      "{'answer': ' The image presents a close-up view of a circular, white background with a blue and brown pattern. The pattern appears to be a microscopic view of a tissue sample, possibly a biopsy, with a complex network of blood vessels and capillaries. The blue areas are concentrated in the center, while the brown areas are more dispersed throughout the image. The pattern is not uniform, with some areas showing more intricate details than others. The image is taken from a slightly elevated angle, providing a comprehensive view of the tissue sample.'}\n",
      "Transformed Style Embedding Shape: torch.Size([1, 256])\n",
      "Style Embedding Extraction:\n",
      " tensor([[-0.0094,  0.0379, -0.0215,  0.0191, -0.0179,  0.0022,  0.0012, -0.0022,\n",
      "          0.0162,  0.0033,  0.0006,  0.0491,  0.0221,  0.0244,  0.0174,  0.0268,\n",
      "         -0.0130, -0.0002, -0.0511,  0.0105, -0.0018, -0.0119, -0.0521, -0.0117,\n",
      "          0.0054, -0.0069, -0.0118,  0.0318,  0.0063,  0.0117,  0.0194,  0.0263,\n",
      "         -0.0278,  0.0203, -0.0284,  0.0267, -0.0184,  0.0201,  0.0199,  0.0178,\n",
      "         -0.0017, -0.0064, -0.0245,  0.0032, -0.0082,  0.0083,  0.0463, -0.0048,\n",
      "          0.0121, -0.0394,  0.0280,  0.0063,  0.0182,  0.0336,  0.0173, -0.0080,\n",
      "         -0.0091,  0.0140,  0.0269, -0.0081, -0.0025,  0.0011,  0.0394, -0.0090,\n",
      "          0.0136, -0.0518,  0.0083, -0.0007, -0.0302, -0.0235,  0.0086,  0.0045,\n",
      "          0.0013, -0.0038, -0.0677,  0.0036,  0.0024, -0.0248, -0.0258, -0.0263,\n",
      "          0.0032,  0.0660,  0.0015, -0.0162, -0.0208,  0.0161, -0.0034, -0.0045,\n",
      "          0.0196,  0.0408,  0.0191,  0.0255,  0.0213,  0.0035, -0.0052,  0.0290,\n",
      "         -0.0038,  0.0261, -0.0130, -0.0154, -0.0064, -0.0489,  0.0003, -0.0208,\n",
      "          0.0378, -0.0275,  0.0419, -0.0429,  0.0415, -0.0509,  0.0094,  0.0031,\n",
      "          0.0054,  0.0027, -0.0020, -0.0013,  0.0067, -0.0130,  0.0034, -0.0316,\n",
      "         -0.0522, -0.0299, -0.0205, -0.0020,  0.0263, -0.0089, -0.0316,  0.0256,\n",
      "         -0.0019,  0.0301,  0.0001,  0.0228, -0.0053,  0.0244, -0.0347,  0.0148,\n",
      "          0.0351,  0.0326,  0.0098, -0.0237, -0.0299, -0.0196, -0.0265,  0.0021,\n",
      "          0.0328,  0.0020,  0.0536, -0.0117,  0.0377,  0.0014, -0.0164,  0.0067,\n",
      "         -0.0030, -0.0251, -0.0079, -0.0185,  0.0068,  0.0411, -0.0242,  0.0139,\n",
      "          0.0106, -0.0106,  0.0009, -0.0005, -0.0342,  0.0065,  0.0123, -0.0337,\n",
      "          0.0053,  0.0097,  0.0120, -0.0202, -0.0088,  0.0191, -0.0069,  0.0223,\n",
      "          0.0317,  0.0129,  0.0267, -0.0163, -0.0051, -0.0178,  0.0150, -0.0261,\n",
      "         -0.0095,  0.0024, -0.0331, -0.0216, -0.0315, -0.0076,  0.0500, -0.0311,\n",
      "          0.0190,  0.0039,  0.0067, -0.0342, -0.0094, -0.0017, -0.0059,  0.0195,\n",
      "          0.0123,  0.0219, -0.0389,  0.0138,  0.0277,  0.0216, -0.0195, -0.0137,\n",
      "          0.0065,  0.0258, -0.0038,  0.0170,  0.0472,  0.0223, -0.0253,  0.0040,\n",
      "          0.0109, -0.0169, -0.0031,  0.0361, -0.0215, -0.0049, -0.0268,  0.0302,\n",
      "         -0.0237, -0.0012, -0.0025,  0.0393,  0.0275,  0.0334,  0.0309,  0.0331,\n",
      "          0.0064, -0.0107, -0.0157,  0.0403,  0.0406,  0.0008,  0.0096, -0.0274,\n",
      "         -0.0178,  0.0456,  0.0333, -0.0141, -0.0131, -0.0032, -0.0100,  0.0183,\n",
      "          0.0395, -0.0157, -0.0057,  0.0409,  0.0211, -0.0177,  0.0013, -0.0020]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Transformed Style Embedding Shape: torch.Size([1, 256])\n",
      "Style Embedding Extraction:\n",
      " tensor([[-0.0140,  0.0077,  0.0403, -0.0254,  0.0120, -0.0103, -0.0369, -0.0196,\n",
      "          0.0118, -0.0062,  0.0478, -0.0330,  0.0033, -0.0166,  0.0271,  0.0145,\n",
      "         -0.0081,  0.0163, -0.0007,  0.0197,  0.0084, -0.0259, -0.0225,  0.0311,\n",
      "         -0.0003,  0.0249,  0.0117,  0.0520,  0.0304, -0.0143, -0.0504, -0.0454,\n",
      "          0.0357,  0.0058, -0.0663, -0.0088, -0.0115,  0.0196,  0.0046, -0.0287,\n",
      "         -0.0025, -0.0020, -0.0287, -0.0204,  0.0166, -0.0227, -0.0306, -0.0262,\n",
      "          0.0015, -0.0121,  0.0177,  0.0139, -0.0067,  0.0329,  0.0181,  0.0353,\n",
      "          0.0102, -0.0215, -0.0155,  0.0352,  0.0153, -0.0152, -0.0123, -0.0254,\n",
      "          0.0047,  0.0319,  0.0112,  0.0116, -0.0269, -0.0117,  0.0114, -0.0356,\n",
      "         -0.0157,  0.0098,  0.0126, -0.0138, -0.0021,  0.0178,  0.0232,  0.0315,\n",
      "          0.0400,  0.0404, -0.0007, -0.0073, -0.0122, -0.0394, -0.0180, -0.0075,\n",
      "         -0.0146, -0.0238, -0.0148,  0.0055,  0.0099,  0.0068,  0.0385, -0.0002,\n",
      "         -0.0350, -0.0046,  0.0267, -0.0404, -0.0048, -0.0101,  0.0427, -0.0141,\n",
      "          0.0002,  0.0355,  0.0360,  0.0365, -0.0426,  0.0183, -0.0379, -0.0186,\n",
      "          0.0337,  0.0174,  0.0157, -0.0110, -0.0246,  0.0277, -0.0153, -0.0023,\n",
      "         -0.0041,  0.0089, -0.0297, -0.0063, -0.0031,  0.0132,  0.0166, -0.0079,\n",
      "          0.0126,  0.0226,  0.0329, -0.0334,  0.0046,  0.0149, -0.0248, -0.0423,\n",
      "          0.0295, -0.0045, -0.0120,  0.0278, -0.0004,  0.0027, -0.0097,  0.0208,\n",
      "          0.0457, -0.0054, -0.0003,  0.0066, -0.0032,  0.0252, -0.0311, -0.0179,\n",
      "         -0.0105, -0.0124,  0.0319, -0.0243,  0.0191,  0.0056,  0.0426,  0.0204,\n",
      "          0.0047, -0.0465,  0.0353, -0.0366,  0.0294, -0.0079,  0.0229,  0.0169,\n",
      "         -0.0294,  0.0338, -0.0030, -0.0160, -0.0430,  0.0003,  0.0128, -0.0283,\n",
      "         -0.0049,  0.0121,  0.0149, -0.0051,  0.0205, -0.0407, -0.0019,  0.0011,\n",
      "          0.0152, -0.0017, -0.0068, -0.0180, -0.0069,  0.0087, -0.0050, -0.0249,\n",
      "         -0.0352, -0.0140,  0.0064, -0.0458, -0.0110, -0.0056,  0.0024,  0.0155,\n",
      "          0.0108, -0.0088, -0.0514,  0.0044,  0.0006,  0.0021, -0.0592, -0.0051,\n",
      "          0.0008, -0.0535,  0.0031,  0.0294, -0.0012,  0.0220, -0.0090,  0.0095,\n",
      "         -0.0322, -0.0188,  0.0379,  0.0170,  0.0120, -0.0031,  0.0353,  0.0213,\n",
      "          0.0358,  0.0379,  0.0113, -0.0126, -0.0230,  0.0002, -0.0229,  0.0248,\n",
      "          0.0173,  0.0445,  0.0090, -0.0082,  0.0021, -0.0199, -0.0228, -0.0060,\n",
      "          0.0052,  0.0101,  0.0098, -0.0078, -0.0217,  0.0023,  0.0145, -0.0324,\n",
      "         -0.0264, -0.0013, -0.0003, -0.0002,  0.0179, -0.0342, -0.0165,  0.0005]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH_SRC = \"/Users/hoangthuyduongvu/Documents/icm/tumor-augmentation/data/HE/A3_TMA_15_02_IVB_HE.png\"\n",
    "describe_img(IMAGE_PATH_SRC)\n",
    "\n",
    "IMAGE_PATH_DST = \"/Users/hoangthuyduongvu/Documents/icm/tumor-augmentation/data/NKX3/A3_TMA_15_02_IB_NKX.png\"\n",
    "describe_img(IMAGE_PATH_DST)\n",
    "\n",
    "print(\"Style Embedding Extraction:\\n\", extract_style_emb(IMAGE_PATH_SRC))\n",
    "print(\"Style Embedding Extraction:\\n\", extract_style_emb(IMAGE_PATH_DST))\n",
    "\n",
    "\n",
    "# Test encoder and decoder\n",
    "encoder = VAEncoder(input_dim=256, output_dim=128)\n",
    "decoder = VAEDecoder(input_dim=128, output_dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(IMAGE_PATH_SRC).resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  9.6327,  -4.2719, -13.0432,  ...,   1.7676,   1.2235, -19.3365],\n",
       "          [  9.6353,  -4.2826, -13.0165,  ...,   1.7955,   1.2272, -19.3576],\n",
       "          [  9.6422,  -4.2810, -13.0237,  ...,   1.8007,   1.2453, -19.3364],\n",
       "          ...,\n",
       "          [  9.5781,  -4.2081, -12.9892,  ...,   1.7764,   1.2251, -19.2830],\n",
       "          [  9.6062,  -4.2406, -13.0135,  ...,   1.8113,   1.2187, -19.2971],\n",
       "          [  9.5092,  -4.2302, -13.1304,  ...,   1.7647,   1.2110, -19.2875]],\n",
       "\n",
       "         [[  9.6320,  -4.3030, -13.0712,  ...,   1.7704,   1.2450, -19.3568],\n",
       "          [  9.6393,  -4.2924, -13.0252,  ...,   1.7885,   1.2500, -19.3704],\n",
       "          [  9.6410,  -4.2791, -13.0302,  ...,   1.7938,   1.2566, -19.3486],\n",
       "          ...,\n",
       "          [  9.5531,  -4.2235, -12.9687,  ...,   1.7344,   1.2137, -19.2820],\n",
       "          [  9.5459,  -4.1971, -13.0273,  ...,   1.7908,   1.2507, -19.2867],\n",
       "          [  9.4205,  -4.2019, -13.2223,  ...,   1.7488,   1.2660, -19.3008]],\n",
       "\n",
       "         [[  9.5483,  -4.2639, -12.8993,  ...,   1.7364,   1.2263, -19.1614],\n",
       "          [  9.5508,  -4.2497, -12.9233,  ...,   1.7932,   1.2300, -19.2019],\n",
       "          [  9.5298,  -4.2510, -12.9532,  ...,   1.7615,   1.2333, -19.1587],\n",
       "          ...,\n",
       "          [  9.5138,  -4.2130, -12.8768,  ...,   1.7604,   1.1793, -19.1018],\n",
       "          [  9.5055,  -4.1331, -12.9353,  ...,   1.7827,   1.2284, -19.1376],\n",
       "          [  9.3906,  -4.1536, -13.0661,  ...,   1.7357,   1.2403, -19.0770]]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.forward(\n",
    "    encoder.forward(\n",
    "    torch.from_numpy(np.array(Image.open(IMAGE_PATH_SRC).resize((256, 256)))).float() \\\n",
    "    .unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tumor-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
